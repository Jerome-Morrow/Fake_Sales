# Автоматизация и деплой (итоговый проект)

## Описание
Проект предназначен для генерации искуственных  данных о продажах N кол-ва магазинов  с использованием библиотеки Faker, 
сохранения их в CSV-файлы и последующей загрузки в базу данных PostgreSQL.  

Файлы с выгрузками должны называться {{shop_num}}_{{cash_num}}.csv. 

Где {{shop_num}} - номер магазина, а {{cash_num}} - номер кассы. В одном магазине может быть несколько  касс - у каждой своя выгрузка. 
Пример названия: 11_2.csv - 11 магазин, 2 касса.
Проект включает в себя скрипты для генерации данных, их обработки и загрузки в БД.

## Установка


Для начала работы с проектом необходимо выполнить несколько шагов по его установке и настройке. 
Ниже приведены инструкции по установке всех необходимых компонентов и запуску проекта.

### Требования
     
     Python 3.8 или выше
     
     pip (менеджер пакетов Python)

#### Установка зависимостей
   
   Клонируйте репозиторий на свой компьютер:

       git clone https://github.com/your-username/your-repo.git
       cd your-repo

   Создайте и активируйте виртуальное окружение (venv):

       python -m venv venv
       source venv/bin/activate  # Для Unix/Linux/macOS
      .\venv\Scripts\activate   # Для Windows    
       
   Установите необходимые Python-пакеты.
   Файл requirements.txt содержит список всех библиотек, необходимых для работы проекта.

       pip install -r requirements.txt

       
## Настройка проекта

  ### Настройте параметры подключения к базе данных :
  
  В файле config.ini укажите параметры подключения к вашей базе данных:

        database
        host = your_host
        database = your_database
        user = your_user
        password = your_password

### Подключение к базе данных Postgres через SSH в DBeaver

##### Откройте DBeaver и создайте новое подключение:

- Database → New Database Connection
  
- В списке выберите PostgreSQL

#### Настройте параметры подключения:

- Введите Host (хост вашего сервера)
        
- Укажите Port (порт, по умолчанию 5432)
          
- Введите Database (имя базы данных)
          
- Укажите User (имя пользователя)
          
- Введите Password (пароль пользователя Postgres)

#### Настройте SSH-туннель:

- Перейдите на вкладку SSH
        
- Установите флажок Use SSH tunnel
        
- Заполните поля:
        
- SSH Host (хост SSH-сервера)
        
- SSH Port (порт SSH, по умолчанию 22)
        
- SSH User (имя пользователя SSH)
        
- SSH Password или SSH Key file (пароль или файл ключа SSH)

#### Проверьте подключение:

- Нажмите Test Connection, чтобы убедиться  подключение работает.
        
- Сохраните подключение:
        
- Если тест прошёл успешно, нажмите Finish для сохранения настроек подключения.
    
###№  Выполнение DDL-запроса для создания таблицы
        
- Откройте редактор SQL:
        
- Выберите созданное подключение к базе данных
        
- Откройте новый редактор SQL
        
- Выполните DDL-запрос из папки DDL


### Преобразуйте файлы Jupyter Notebook в Python-скрипты:
  
  Для преобразования файлов Fake_data_upload.ipynb и fake_data_creation.ipynb в Python-скрипты ,
  
  используйте nbconvert:
      
      pip install nbconvert
      jupyter nbconvert --to script Fake_data_upload.ipynb
      jupyter nbconvert --to script fake_data_creation.ipynb

      
 ### Настройте параметры создаваемого массива данных:

 В разделе [Array_Dimension] файла 'config' задайте кол-во магазинов и количество генерируемых строк  искуственных данных для  каждого магазина:

      [Array_Dimension]
      SHOP_QTY=10
      NUM_RECORDS=100

 ## Запуск

 Для автоматического запуска скрипта   можно использовать следующую запись в crontab:
 
 Первая строка  указывает на то, что скрипт fake_data_creation.py будет запускаться каждый будний день (с понедельника по субботу) в 9:00 утра
 
 Вторая строка  указывает на то,что скрипт Fake_data_upload.py будет запускаться каждый день в 10:00 утра
 
 Использование команды cd /home/Fake_Sales && необходимо  для установки правильного рабочего каталога перед запуском скрипта через crontab 
 Это гарантирует , что скрипт будет искать файлы в ожидаемом месте и позволит избежать  ошибок с  путями к файлам.
 

      00 9 * * 1-6 cd /home/Fake_Sales && /home/Fake_Sales/venv/bin/python3 /home/Fake_Sales/fake_data_creation.py
      00 10 * * *  cd /home/Fake_Sales && /home/Fake_Sales/venv/bin/python3 /home/Fake_Sales/Fake_data_upload.py      

## Использование
Проект автоматически генерирует данные о продажах, сохраняет их в CSV-файлы в указанной папке и загружает в базу данных PostgreSQL. После загрузки данные из папки удаляются.

Основные функции:

- [x] генерация искуственных  данных о продажах N-колличества магазинов
- [x] сохранение данных в CSV-файлы
- [x] загрузка данных в базу данных PostgreSQL
- [x] очистка папки после загрузки данных
            
      

## Структура проекта

 /home/Fake_Sales
 
├── config.ini   - файл конфигурации, содержащий настройки для проекта.

├── Data         - папка для хранения  сгенерированных данных по продажам.

├── DDL          - папка для  храниени DDL запроса для  создания  таблицы в базе данных

├── Img          -папка для скринов (база до выполнения скрипта, после а также скрин CronTaB в PowerShell

├── fake_data_creation.py -скрипт для генерации искуственных  данных о продажах с использованием библиотеки Faker.

├── Fake_data_upload.py -скрипт для загрузки сгенерированных данных в базу данных PostgreSQL.

└── venv -виртуальное окружение Python, содержащее все необходимые зависимости для проекта.

 ## Конфигурация

Настройки проекта хранятся в файле config.ini. 

Необходимо указать путь к папке для хранения CSV-файлов и параметры подключения к базе данных PostgreSQL.

    



    
 
    
     
        

